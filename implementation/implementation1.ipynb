{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69f933f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dataset (Bangla ( Bengali ) sentiment analysis classification benchmark dataset corpus) : https://data.mendeley.com/datasets/p6zc7krs37/4\n",
    "\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8966bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 positive sentences\n",
      "3307 negative sentences\n",
      "3307 positive sentences\n",
      "3307 negative sentences\n"
     ]
    }
   ],
   "source": [
    "# Loading Bangla ( Bengali ) sentiment analysis classification benchmark dataset\n",
    "positive_sentences = []\n",
    "f = open('../datasets/all_positive_8500.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    positive_sentences.append(line.strip())\n",
    "\n",
    "negative_sentences = []\n",
    "f = open('../datasets/all_negative_3307.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    negative_sentences.append(line.strip())\n",
    "    \n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "import random\n",
    "random.shuffle(positive_sentences)\n",
    "\n",
    "for i in range(len(positive_sentences)-len(negative_sentences)):\n",
    "    positive_sentences.pop(0)\n",
    "\n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "\n",
    "y_pos = [1 for i in range(len(positive_sentences))]\n",
    "y_neg = [0 for i in range(len(negative_sentences))]\n",
    "\n",
    "X = positive_sentences + negative_sentences\n",
    "y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0c24841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229077\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4113e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train_val = X_train\n",
    "y_train_val = y_train\n",
    "\n",
    "y_train_val_e = to_categorical(y_train_val)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_val_e, test_size=0.2, random_state=1, stratify=y_train_val_e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "747457da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "632fd6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 228, 300)          68723100  \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 228, 600)          540600    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 228, 600)         2400      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 114, 600)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 114, 800)          1440800   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 114, 800)         3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 57, 800)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 57, 1000)          2401000   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 57, 1000)         4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 28, 1000)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 28, 1200)          3601200   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 28, 1200)         4800      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 1200)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1200)              1441200   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 600)               720600    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 600)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               180300    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,093,502\n",
      "Trainable params: 10,363,202\n",
      "Non-trainable params: 68,730,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.5968\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49953, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 17s 99ms/step - loss: 0.6653 - accuracy: 0.5969 - val_loss: 0.7268 - val_accuracy: 0.4995\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8034\n",
      "Epoch 2: val_accuracy improved from 0.49953 to 0.50991, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 14s 104ms/step - loss: 0.4302 - accuracy: 0.8034 - val_loss: 1.1695 - val_accuracy: 0.5099\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9138\n",
      "Epoch 3: val_accuracy did not improve from 0.50991\n",
      "133/133 [==============================] - 13s 95ms/step - loss: 0.2228 - accuracy: 0.9138 - val_loss: 2.7880 - val_accuracy: 0.5014\n",
      "Epoch 4/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.9609\n",
      "Epoch 4: val_accuracy improved from 0.50991 to 0.79131, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 13s 101ms/step - loss: 0.1102 - accuracy: 0.9610 - val_loss: 0.4638 - val_accuracy: 0.7913\n",
      "Epoch 5/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9804\n",
      "Epoch 5: val_accuracy did not improve from 0.79131\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 5.0773 - val_accuracy: 0.5297\n",
      "Epoch 6/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9768\n",
      "Epoch 6: val_accuracy did not improve from 0.79131\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 6.4691 - val_accuracy: 0.5033\n",
      "Epoch 7/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9794\n",
      "Epoch 7: val_accuracy did not improve from 0.79131\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0580 - accuracy: 0.9794 - val_loss: 7.9183 - val_accuracy: 0.5061\n",
      "Epoch 8/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9832\n",
      "Epoch 8: val_accuracy did not improve from 0.79131\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 21.1364 - val_accuracy: 0.5014\n",
      "Epoch 9/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9927\n",
      "Epoch 9: val_accuracy did not improve from 0.79131\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 5.3583 - val_accuracy: 0.5515\n",
      "Epoch 10/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9848\n",
      "Epoch 10: val_accuracy improved from 0.79131 to 0.86969, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 12s 92ms/step - loss: 0.0524 - accuracy: 0.9849 - val_loss: 0.3628 - val_accuracy: 0.8697\n",
      "Epoch 11/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9927\n",
      "Epoch 11: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 24.8502 - val_accuracy: 0.5014\n",
      "Epoch 12/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9851\n",
      "Epoch 12: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 11.8818 - val_accuracy: 0.5109\n",
      "Epoch 13/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9915\n",
      "Epoch 13: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 20.2092 - val_accuracy: 0.5014\n",
      "Epoch 14/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9969\n",
      "Epoch 14: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 5.0542 - val_accuracy: 0.5316\n",
      "Epoch 15/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 15: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 13.1575 - val_accuracy: 0.5024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9934\n",
      "Epoch 16: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 4.7627 - val_accuracy: 0.5552\n",
      "Epoch 17/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9943\n",
      "Epoch 17: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.5894 - val_accuracy: 0.8602\n",
      "Epoch 18/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9931\n",
      "Epoch 18: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 19.1760 - val_accuracy: 0.5014\n",
      "Epoch 19/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9927\n",
      "Epoch 19: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 13.4787 - val_accuracy: 0.5024\n",
      "Epoch 20/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9943\n",
      "Epoch 20: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 11.3253 - val_accuracy: 0.5099\n",
      "Epoch 21/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 21: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 28.7444 - val_accuracy: 0.5005\n",
      "Epoch 22/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 22: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.6230 - val_accuracy: 0.8678\n",
      "Epoch 23/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9948\n",
      "Epoch 23: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.3968 - val_accuracy: 0.8621\n",
      "Epoch 24/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9893\n",
      "Epoch 24: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0405 - accuracy: 0.9894 - val_loss: 0.7118 - val_accuracy: 0.7781\n",
      "Epoch 25/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9927\n",
      "Epoch 25: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 18.3540 - val_accuracy: 0.5005\n",
      "Epoch 26/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9941\n",
      "Epoch 26: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 4.3125 - val_accuracy: 0.5326\n",
      "Epoch 27/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 27: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 12.5606 - val_accuracy: 0.5024\n",
      "Epoch 28/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 28: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 10.5648 - val_accuracy: 0.5014\n",
      "Epoch 29/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 29: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 3.8286 - val_accuracy: 0.5836\n",
      "Epoch 30/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 30: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 17.4399 - val_accuracy: 0.5005\n",
      "Epoch 31/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 31: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 11.9303 - val_accuracy: 0.5071\n",
      "Epoch 32/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 32: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.6994 - val_accuracy: 0.8196\n",
      "Epoch 33/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9960\n",
      "Epoch 33: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 16.7614 - val_accuracy: 0.5005\n",
      "Epoch 34/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9915\n",
      "Epoch 34: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.6170 - val_accuracy: 0.8244\n",
      "Epoch 35/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 35: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.8243 - val_accuracy: 0.7970\n",
      "Epoch 36/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9865\n",
      "Epoch 36: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 14.0397 - val_accuracy: 0.5024\n",
      "Epoch 37/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 37: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 5.5679 - val_accuracy: 0.5222\n",
      "Epoch 38/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 38: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.2523 - val_accuracy: 0.7554\n",
      "Epoch 39/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 39: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 21.9753 - val_accuracy: 0.5005\n",
      "Epoch 40/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9910\n",
      "Epoch 40: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0340 - accuracy: 0.9910 - val_loss: 13.6357 - val_accuracy: 0.5014\n",
      "Epoch 41/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 41: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 82ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 17.1835 - val_accuracy: 0.5024\n",
      "Epoch 42/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9960\n",
      "Epoch 42: val_accuracy did not improve from 0.86969\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 15.7132 - val_accuracy: 0.5014\n",
      "Epoch 43/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 43: val_accuracy improved from 0.86969 to 0.87724, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 12s 92ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.5080 - val_accuracy: 0.8772\n",
      "Epoch 44/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 44: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 8.7808 - val_accuracy: 0.5288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 26.4348 - val_accuracy: 0.5005\n",
      "Epoch 46/50\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 46: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 11.6545 - val_accuracy: 0.5052\n",
      "Epoch 47/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9960\n",
      "Epoch 47: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 45.5224 - val_accuracy: 0.4995\n",
      "Epoch 48/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9936\n",
      "Epoch 48: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 19.7822 - val_accuracy: 0.5024\n",
      "Epoch 49/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9948\n",
      "Epoch 49: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 4.6056 - val_accuracy: 0.5703\n",
      "Epoch 50/50\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 50: val_accuracy did not improve from 0.87724\n",
      "133/133 [==============================] - 11s 81ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 23.7990 - val_accuracy: 0.5024\n"
     ]
    }
   ],
   "source": [
    "def nlp_cnn(w2v):\n",
    "    inputs = Input(shape=(X_train[0].shape[-1],))\n",
    "\n",
    "    embedding_layer = gensim_to_keras_embedding(w2v)\n",
    "    \n",
    "    embedding_layer = embedding_layer(inputs)\n",
    "\n",
    "    conv = Conv1D(600, 3, padding='same', activation='relu')(embedding_layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(800, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "    \n",
    "    conv = Conv1D(1000, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(1200, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    output = GlobalAveragePooling1D()(conv)\n",
    "\n",
    "    output = Dense(units=1200, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=600, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=300, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=100, activation='relu')(output)\n",
    "    output = Dense(units=2, activation='sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = nlp_cnn(w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('./model1.h5', save_freq=\"epoch\",  verbose=1, monitor='val_accuracy', save_best_only=True,\n",
    "    save_weights_only=False)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd72a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c150a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model1.h5')\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0acf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT OF CNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       661\n",
      "           1       0.89      0.90      0.89       662\n",
      "\n",
      "    accuracy                           0.89      1323\n",
      "   macro avg       0.89      0.89      0.89      1323\n",
      "weighted avg       0.89      0.89      0.89      1323\n",
      "\n",
      "0.8926681783824642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT OF CNN\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e621101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2 0\n",
      "embedding_1 1\n",
      "conv1d_4 2\n",
      "batch_normalization_4 3\n",
      "max_pooling1d_3 4\n",
      "conv1d_5 5\n",
      "batch_normalization_5 6\n",
      "max_pooling1d_4 7\n",
      "conv1d_6 8\n",
      "batch_normalization_6 9\n",
      "max_pooling1d_5 10\n",
      "conv1d_7 11\n",
      "batch_normalization_7 12\n",
      "global_average_pooling1d_1 13\n",
      "dense_5 14\n",
      "dropout_3 15\n",
      "dense_6 16\n",
      "dropout_4 17\n",
      "dense_7 18\n",
      "dropout_5 19\n",
      "dense_8 20\n",
      "dense_9 21\n",
      "166/166 [==============================] - 3s 15ms/step\n",
      "42/42 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(layer.name, i)\n",
    "f = Model(model.input, model.layers[13].output)\n",
    "fe_train_val = f.predict(X_train_val)\n",
    "fe_test = f.predict(X_test)\n",
    "\n",
    "\n",
    "def flatten_features(x):\n",
    "    x_flatten = []\n",
    "    for f in x:\n",
    "        f = f.flatten()\n",
    "        x_flatten.append(f)\n",
    "    x_flatten = np.array(x_flatten)\n",
    "    return x_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0594cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "f_train_val = flatten_features(fe_train_val) # Doesn't put any effect if flatten/global average pooling used\n",
    "f_test = flatten_features(fe_test)\n",
    "\n",
    "# f_train_val = scaler.fit_transform(fe_train_val)\n",
    "# f_test = scaler.fit_transform(fe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80cc4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 1/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.968) total time=   0.0s\n",
      "[CV 2/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 2/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.955) total time=   0.0s\n",
      "[CV 3/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 3/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.964) total time=   0.0s\n",
      "[CV 4/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 4/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.966) total time=   0.0s\n",
      "[CV 5/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 5/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.970) total time=   0.0s\n",
      "[CV 1/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 1/5; 2/49] END n_neighbors=2;, score=(train=0.982, test=0.960) total time=   0.0s\n",
      "[CV 2/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 2/5; 2/49] END n_neighbors=2;, score=(train=0.984, test=0.953) total time=   0.0s\n",
      "[CV 3/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 3/5; 2/49] END n_neighbors=2;, score=(train=0.981, test=0.972) total time=   0.0s\n",
      "[CV 4/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 4/5; 2/49] END n_neighbors=2;, score=(train=0.979, test=0.981) total time=   0.0s\n",
      "[CV 5/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 5/5; 2/49] END n_neighbors=2;, score=(train=0.983, test=0.970) total time=   0.0s\n",
      "[CV 1/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 1/5; 3/49] END n_neighbors=3;, score=(train=0.984, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 2/5; 3/49] END n_neighbors=3;, score=(train=0.983, test=0.966) total time=   0.0s\n",
      "[CV 3/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 3/5; 3/49] END n_neighbors=3;, score=(train=0.983, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 4/5; 3/49] END n_neighbors=3;, score=(train=0.980, test=0.974) total time=   0.0s\n",
      "[CV 5/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 5/5; 3/49] END n_neighbors=3;, score=(train=0.983, test=0.977) total time=   0.0s\n",
      "[CV 1/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 1/5; 4/49] END n_neighbors=4;, score=(train=0.982, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 2/5; 4/49] END n_neighbors=4;, score=(train=0.983, test=0.960) total time=   0.0s\n",
      "[CV 3/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 3/5; 4/49] END n_neighbors=4;, score=(train=0.981, test=0.979) total time=   0.0s\n",
      "[CV 4/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 4/5; 4/49] END n_neighbors=4;, score=(train=0.978, test=0.981) total time=   0.0s\n",
      "[CV 5/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 5/5; 4/49] END n_neighbors=4;, score=(train=0.982, test=0.979) total time=   0.0s\n",
      "[CV 1/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 1/5; 5/49] END n_neighbors=5;, score=(train=0.981, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 2/5; 5/49] END n_neighbors=5;, score=(train=0.983, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 3/5; 5/49] END n_neighbors=5;, score=(train=0.982, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 4/5; 5/49] END n_neighbors=5;, score=(train=0.980, test=0.977) total time=   0.0s\n",
      "[CV 5/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 5/5; 5/49] END n_neighbors=5;, score=(train=0.979, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 1/5; 6/49] END n_neighbors=6;, score=(train=0.982, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 2/5; 6/49] END n_neighbors=6;, score=(train=0.983, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 3/5; 6/49] END n_neighbors=6;, score=(train=0.980, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 4/5; 6/49] END n_neighbors=6;, score=(train=0.979, test=0.985) total time=   0.0s\n",
      "[CV 5/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 5/5; 6/49] END n_neighbors=6;, score=(train=0.978, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 1/5; 7/49] END n_neighbors=7;, score=(train=0.982, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 2/5; 7/49] END n_neighbors=7;, score=(train=0.982, test=0.972) total time=   0.0s\n",
      "[CV 3/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 3/5; 7/49] END n_neighbors=7;, score=(train=0.982, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 4/5; 7/49] END n_neighbors=7;, score=(train=0.979, test=0.981) total time=   0.0s\n",
      "[CV 5/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 5/5; 7/49] END n_neighbors=7;, score=(train=0.979, test=0.979) total time=   0.0s\n",
      "[CV 1/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 1/5; 8/49] END n_neighbors=8;, score=(train=0.982, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 2/5; 8/49] END n_neighbors=8;, score=(train=0.981, test=0.966) total time=   0.0s\n",
      "[CV 3/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 3/5; 8/49] END n_neighbors=8;, score=(train=0.981, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 4/5; 8/49] END n_neighbors=8;, score=(train=0.976, test=0.983) total time=   0.0s\n",
      "[CV 5/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 5/5; 8/49] END n_neighbors=8;, score=(train=0.978, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 1/5; 9/49] END n_neighbors=9;, score=(train=0.981, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 2/5; 9/49] END n_neighbors=9;, score=(train=0.980, test=0.970) total time=   0.0s\n",
      "[CV 3/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 3/5; 9/49] END n_neighbors=9;, score=(train=0.981, test=0.977) total time=   0.0s\n",
      "[CV 4/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 4/5; 9/49] END n_neighbors=9;, score=(train=0.977, test=0.985) total time=   0.0s\n",
      "[CV 5/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 5/5; 9/49] END n_neighbors=9;, score=(train=0.979, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 1/5; 10/49] END n_neighbors=10;, score=(train=0.981, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 2/5; 10/49] END n_neighbors=10;, score=(train=0.980, test=0.968) total time=   0.0s\n",
      "[CV 3/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 3/5; 10/49] END n_neighbors=10;, score=(train=0.982, test=0.977) total time=   0.0s\n",
      "[CV 4/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 4/5; 10/49] END n_neighbors=10;, score=(train=0.976, test=0.989) total time=   0.0s\n",
      "[CV 5/5; 10/49] START n_neighbors=10............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/49] END n_neighbors=10;, score=(train=0.979, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 1/5; 11/49] END n_neighbors=11;, score=(train=0.982, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 2/5; 11/49] END n_neighbors=11;, score=(train=0.979, test=0.968) total time=   0.0s\n",
      "[CV 3/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 3/5; 11/49] END n_neighbors=11;, score=(train=0.980, test=0.974) total time=   0.0s\n",
      "[CV 4/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 4/5; 11/49] END n_neighbors=11;, score=(train=0.977, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 5/5; 11/49] END n_neighbors=11;, score=(train=0.978, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 1/5; 12/49] END n_neighbors=12;, score=(train=0.979, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 2/5; 12/49] END n_neighbors=12;, score=(train=0.979, test=0.966) total time=   0.0s\n",
      "[CV 3/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 3/5; 12/49] END n_neighbors=12;, score=(train=0.980, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 4/5; 12/49] END n_neighbors=12;, score=(train=0.976, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 5/5; 12/49] END n_neighbors=12;, score=(train=0.976, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 1/5; 13/49] END n_neighbors=13;, score=(train=0.980, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 2/5; 13/49] END n_neighbors=13;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 3/5; 13/49] END n_neighbors=13;, score=(train=0.979, test=0.974) total time=   0.0s\n",
      "[CV 4/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 4/5; 13/49] END n_neighbors=13;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 5/5; 13/49] END n_neighbors=13;, score=(train=0.975, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 1/5; 14/49] END n_neighbors=14;, score=(train=0.980, test=0.968) total time=   0.0s\n",
      "[CV 2/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 2/5; 14/49] END n_neighbors=14;, score=(train=0.979, test=0.962) total time=   0.0s\n",
      "[CV 3/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 3/5; 14/49] END n_neighbors=14;, score=(train=0.979, test=0.974) total time=   0.0s\n",
      "[CV 4/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 4/5; 14/49] END n_neighbors=14;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 5/5; 14/49] END n_neighbors=14;, score=(train=0.975, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 1/5; 15/49] END n_neighbors=15;, score=(train=0.978, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 2/5; 15/49] END n_neighbors=15;, score=(train=0.980, test=0.962) total time=   0.0s\n",
      "[CV 3/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 3/5; 15/49] END n_neighbors=15;, score=(train=0.978, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 4/5; 15/49] END n_neighbors=15;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 5/5; 15/49] END n_neighbors=15;, score=(train=0.975, test=0.979) total time=   0.0s\n",
      "[CV 1/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 1/5; 16/49] END n_neighbors=16;, score=(train=0.978, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 2/5; 16/49] END n_neighbors=16;, score=(train=0.980, test=0.962) total time=   0.0s\n",
      "[CV 3/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 3/5; 16/49] END n_neighbors=16;, score=(train=0.979, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 4/5; 16/49] END n_neighbors=16;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 5/5; 16/49] END n_neighbors=16;, score=(train=0.974, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 1/5; 17/49] END n_neighbors=17;, score=(train=0.978, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 2/5; 17/49] END n_neighbors=17;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 3/5; 17/49] END n_neighbors=17;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 4/5; 17/49] END n_neighbors=17;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 5/5; 17/49] END n_neighbors=17;, score=(train=0.974, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 1/5; 18/49] END n_neighbors=18;, score=(train=0.978, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 2/5; 18/49] END n_neighbors=18;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 3/5; 18/49] END n_neighbors=18;, score=(train=0.978, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 4/5; 18/49] END n_neighbors=18;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 5/5; 18/49] END n_neighbors=18;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 1/5; 19/49] END n_neighbors=19;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 2/5; 19/49] END n_neighbors=19;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 3/5; 19/49] END n_neighbors=19;, score=(train=0.978, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 4/5; 19/49] END n_neighbors=19;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 5/5; 19/49] END n_neighbors=19;, score=(train=0.975, test=0.981) total time=   0.0s\n",
      "[CV 1/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 1/5; 20/49] END n_neighbors=20;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 2/5; 20/49] END n_neighbors=20;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 3/5; 20/49] END n_neighbors=20;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 20/49] START n_neighbors=20............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/49] END n_neighbors=20;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 5/5; 20/49] END n_neighbors=20;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 1/5; 21/49] END n_neighbors=21;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 2/5; 21/49] END n_neighbors=21;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 3/5; 21/49] END n_neighbors=21;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 4/5; 21/49] END n_neighbors=21;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 5/5; 21/49] END n_neighbors=21;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 1/5; 22/49] END n_neighbors=22;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 2/5; 22/49] END n_neighbors=22;, score=(train=0.979, test=0.966) total time=   0.0s\n",
      "[CV 3/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 3/5; 22/49] END n_neighbors=22;, score=(train=0.976, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 4/5; 22/49] END n_neighbors=22;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 5/5; 22/49] END n_neighbors=22;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 1/5; 23/49] END n_neighbors=23;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 2/5; 23/49] END n_neighbors=23;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 3/5; 23/49] END n_neighbors=23;, score=(train=0.976, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 4/5; 23/49] END n_neighbors=23;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 5/5; 23/49] END n_neighbors=23;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 1/5; 24/49] END n_neighbors=24;, score=(train=0.977, test=0.970) total time=   0.0s\n",
      "[CV 2/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 2/5; 24/49] END n_neighbors=24;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 3/5; 24/49] END n_neighbors=24;, score=(train=0.976, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 4/5; 24/49] END n_neighbors=24;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 5/5; 24/49] END n_neighbors=24;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 1/5; 25/49] END n_neighbors=25;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 2/5; 25/49] END n_neighbors=25;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 3/5; 25/49] END n_neighbors=25;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 4/5; 25/49] END n_neighbors=25;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 5/5; 25/49] END n_neighbors=25;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 1/5; 26/49] END n_neighbors=26;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 2/5; 26/49] END n_neighbors=26;, score=(train=0.979, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 3/5; 26/49] END n_neighbors=26;, score=(train=0.976, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 4/5; 26/49] END n_neighbors=26;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 5/5; 26/49] END n_neighbors=26;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 1/5; 27/49] END n_neighbors=27;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 2/5; 27/49] END n_neighbors=27;, score=(train=0.980, test=0.966) total time=   0.0s\n",
      "[CV 3/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 3/5; 27/49] END n_neighbors=27;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 4/5; 27/49] END n_neighbors=27;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 5/5; 27/49] END n_neighbors=27;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 1/5; 28/49] END n_neighbors=28;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 2/5; 28/49] END n_neighbors=28;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 3/5; 28/49] END n_neighbors=28;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 4/5; 28/49] END n_neighbors=28;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 5/5; 28/49] END n_neighbors=28;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 1/5; 29/49] END n_neighbors=29;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 2/5; 29/49] END n_neighbors=29;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 3/5; 29/49] END n_neighbors=29;, score=(train=0.978, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 4/5; 29/49] END n_neighbors=29;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 5/5; 29/49] END n_neighbors=29;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 1/5; 30/49] END n_neighbors=30;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 2/5; 30/49] END n_neighbors=30;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 30/49] START n_neighbors=30............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/49] END n_neighbors=30;, score=(train=0.978, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 4/5; 30/49] END n_neighbors=30;, score=(train=0.973, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 5/5; 30/49] END n_neighbors=30;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 1/5; 31/49] END n_neighbors=31;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 2/5; 31/49] END n_neighbors=31;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 3/5; 31/49] END n_neighbors=31;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 4/5; 31/49] END n_neighbors=31;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 5/5; 31/49] END n_neighbors=31;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 1/5; 32/49] END n_neighbors=32;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 2/5; 32/49] END n_neighbors=32;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 3/5; 32/49] END n_neighbors=32;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 4/5; 32/49] END n_neighbors=32;, score=(train=0.973, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 5/5; 32/49] END n_neighbors=32;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 1/5; 33/49] END n_neighbors=33;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 2/5; 33/49] END n_neighbors=33;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 3/5; 33/49] END n_neighbors=33;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 4/5; 33/49] END n_neighbors=33;, score=(train=0.973, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 5/5; 33/49] END n_neighbors=33;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 1/5; 34/49] END n_neighbors=34;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 2/5; 34/49] END n_neighbors=34;, score=(train=0.980, test=0.962) total time=   0.0s\n",
      "[CV 3/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 3/5; 34/49] END n_neighbors=34;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 4/5; 34/49] END n_neighbors=34;, score=(train=0.973, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 5/5; 34/49] END n_neighbors=34;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 1/5; 35/49] END n_neighbors=35;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 2/5; 35/49] END n_neighbors=35;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 3/5; 35/49] END n_neighbors=35;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 4/5; 35/49] END n_neighbors=35;, score=(train=0.973, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 5/5; 35/49] END n_neighbors=35;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 1/5; 36/49] END n_neighbors=36;, score=(train=0.977, test=0.972) total time=   0.0s\n",
      "[CV 2/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 2/5; 36/49] END n_neighbors=36;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 3/5; 36/49] END n_neighbors=36;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 4/5; 36/49] END n_neighbors=36;, score=(train=0.973, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 5/5; 36/49] END n_neighbors=36;, score=(train=0.974, test=0.983) total time=   0.1s\n",
      "[CV 1/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 1/5; 37/49] END n_neighbors=37;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 2/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 2/5; 37/49] END n_neighbors=37;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 3/5; 37/49] END n_neighbors=37;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 4/5; 37/49] END n_neighbors=37;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 5/5; 37/49] END n_neighbors=37;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 1/5; 38/49] END n_neighbors=38;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 2/5; 38/49] END n_neighbors=38;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 3/5; 38/49] END n_neighbors=38;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 4/5; 38/49] END n_neighbors=38;, score=(train=0.974, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 5/5; 38/49] END n_neighbors=38;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 1/5; 39/49] END n_neighbors=39;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 2/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 2/5; 39/49] END n_neighbors=39;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 3/5; 39/49] END n_neighbors=39;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 4/5; 39/49] END n_neighbors=39;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 5/5; 39/49] END n_neighbors=39;, score=(train=0.974, test=0.983) total time=   0.1s\n",
      "[CV 1/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 1/5; 40/49] END n_neighbors=40;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 40/49] START n_neighbors=40............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/49] END n_neighbors=40;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 3/5; 40/49] END n_neighbors=40;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 4/5; 40/49] END n_neighbors=40;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 5/5; 40/49] END n_neighbors=40;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 1/5; 41/49] END n_neighbors=41;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 2/5; 41/49] END n_neighbors=41;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 3/5; 41/49] END n_neighbors=41;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 4/5; 41/49] END n_neighbors=41;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 5/5; 41/49] END n_neighbors=41;, score=(train=0.974, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 1/5; 42/49] END n_neighbors=42;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 2/5; 42/49] END n_neighbors=42;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 3/5; 42/49] END n_neighbors=42;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 4/5; 42/49] END n_neighbors=42;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 5/5; 42/49] END n_neighbors=42;, score=(train=0.975, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 1/5; 43/49] END n_neighbors=43;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 2/5; 43/49] END n_neighbors=43;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 3/5; 43/49] END n_neighbors=43;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 4/5; 43/49] END n_neighbors=43;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 5/5; 43/49] END n_neighbors=43;, score=(train=0.975, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 1/5; 44/49] END n_neighbors=44;, score=(train=0.977, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 2/5; 44/49] END n_neighbors=44;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 3/5; 44/49] END n_neighbors=44;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 4/5; 44/49] END n_neighbors=44;, score=(train=0.974, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 5/5; 44/49] END n_neighbors=44;, score=(train=0.975, test=0.983) total time=   0.0s\n",
      "[CV 1/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 1/5; 45/49] END n_neighbors=45;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 2/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 2/5; 45/49] END n_neighbors=45;, score=(train=0.980, test=0.964) total time=   0.0s\n",
      "[CV 3/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 3/5; 45/49] END n_neighbors=45;, score=(train=0.976, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 4/5; 45/49] END n_neighbors=45;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 5/5; 45/49] END n_neighbors=45;, score=(train=0.975, test=0.983) total time=   0.1s\n",
      "[CV 1/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 1/5; 46/49] END n_neighbors=46;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 2/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 2/5; 46/49] END n_neighbors=46;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 3/5; 46/49] END n_neighbors=46;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 4/5; 46/49] END n_neighbors=46;, score=(train=0.974, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 5/5; 46/49] END n_neighbors=46;, score=(train=0.975, test=0.983) total time=   0.1s\n",
      "[CV 1/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 1/5; 47/49] END n_neighbors=47;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 2/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 2/5; 47/49] END n_neighbors=47;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 3/5; 47/49] END n_neighbors=47;, score=(train=0.977, test=0.975) total time=   0.1s\n",
      "[CV 4/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 4/5; 47/49] END n_neighbors=47;, score=(train=0.975, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 5/5; 47/49] END n_neighbors=47;, score=(train=0.975, test=0.981) total time=   0.1s\n",
      "[CV 1/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 1/5; 48/49] END n_neighbors=48;, score=(train=0.978, test=0.974) total time=   0.1s\n",
      "[CV 2/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 2/5; 48/49] END n_neighbors=48;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 3/5; 48/49] END n_neighbors=48;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 4/5; 48/49] END n_neighbors=48;, score=(train=0.975, test=0.987) total time=   0.0s\n",
      "[CV 5/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 5/5; 48/49] END n_neighbors=48;, score=(train=0.975, test=0.983) total time=   0.1s\n",
      "[CV 1/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 1/5; 49/49] END n_neighbors=49;, score=(train=0.978, test=0.974) total time=   0.0s\n",
      "[CV 2/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 2/5; 49/49] END n_neighbors=49;, score=(train=0.980, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 3/5; 49/49] END n_neighbors=49;, score=(train=0.977, test=0.975) total time=   0.0s\n",
      "[CV 4/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 4/5; 49/49] END n_neighbors=49;, score=(train=0.975, test=0.987) total time=   0.1s\n",
      "[CV 5/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 5/5; 49/49] END n_neighbors=49;, score=(train=0.975, test=0.983) total time=   0.0s\n",
      "{'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 50))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=True,verbose=10)\n",
    "\n",
    "\n",
    "X_traingcv, X_testgcv, y_traingcv, y_testgcv = train_test_split(f_train_val, y_train_val, test_size=0.5, random_state=1, stratify=y_train_val)\n",
    "\n",
    "grid_search=grid.fit(X_traingcv, y_traingcv)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37f4fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighbors = []\n",
    "l = []\n",
    "for i, p in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    neighbors.append({'neighbor': i+1, 'score': p})\n",
    "    l.append(i+1)\n",
    "\n",
    "neighbors.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(l,grid.cv_results_['mean_test_score'])\n",
    "ax.set_ylim([0.95, 0.98])\n",
    "plt.title('GridSearchCV Results')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Nearest Neighbor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9afbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       661\n",
      "           1       0.91      0.89      0.90       662\n",
      "\n",
      "    accuracy                           0.90      1323\n",
      "   macro avg       0.90      0.90      0.90      1323\n",
      "weighted avg       0.90      0.90      0.90      1323\n",
      "\n",
      "KNN 0.8964474678760394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "knn.fit(f_train_val, y_train_val)\n",
    "preds = knn.predict(f_test)\n",
    "preds_proba = knn.predict_proba(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14510656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=neighbors[1]['neighbor'])\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=neighbors[2]['neighbor'])\n",
    "\n",
    "knn4 = KNeighborsClassifier(n_neighbors=neighbors[3]['neighbor'])\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=neighbors[4]['neighbor'])\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('knn1', knn1),\n",
    "                                     ('knn2', knn2),\n",
    "                                     ('knn3', knn3),\n",
    "                                     ('knn4', knn4),\n",
    "                                     ('knn5', knn5),\n",
    "                                    ], voting='hard')\n",
    "\n",
    "eclf1.fit(f_train_val, y_train_val)\n",
    "\n",
    "preds = eclf1.predict(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f11ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       661\n",
      "           1       0.91      0.89      0.90       662\n",
      "\n",
      "    accuracy                           0.90      1323\n",
      "   macro avg       0.90      0.90      0.90      1323\n",
      "weighted avg       0.90      0.90      0.90      1323\n",
      "\n",
      "KNN VOTING 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN VOTING\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe0c01c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       661\n",
      "           1       0.90      0.89      0.90       662\n",
      "\n",
      "    accuracy                           0.90      1323\n",
      "   macro avg       0.90      0.90      0.90      1323\n",
      "weighted avg       0.90      0.90      0.90      1323\n",
      "\n",
      "SVM  0.8987150415721844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly')\n",
    "svclassifier.fit(f_train_val, y_train_val)\n",
    "preds = svclassifier.predict(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"SVM \", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb132767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
