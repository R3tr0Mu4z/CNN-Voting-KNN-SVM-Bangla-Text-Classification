{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f933f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Dataset (Bangla ( Bengali ) sentiment analysis classification benchmark dataset corpus) : https://data.mendeley.com/datasets/p6zc7krs37/4\n",
    "\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8966bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500 positive sentences\n",
      "3307 negative sentences\n",
      "3307 positive sentences\n",
      "3307 negative sentences\n"
     ]
    }
   ],
   "source": [
    "# Loading Bangla ( Bengali ) sentiment analysis classification benchmark dataset\n",
    "positive_sentences = []\n",
    "f = open('../datasets/all_positive_8500.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    positive_sentences.append(line.strip())\n",
    "\n",
    "negative_sentences = []\n",
    "f = open('../datasets/all_negative_3307.txt','r', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    negative_sentences.append(line.strip())\n",
    "    \n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "import random\n",
    "random.shuffle(positive_sentences)\n",
    "\n",
    "for i in range(len(positive_sentences)-len(negative_sentences)):\n",
    "    positive_sentences.pop(0)\n",
    "\n",
    "print(len(positive_sentences), 'positive sentences')\n",
    "print(len(negative_sentences), 'negative sentences')\n",
    "\n",
    "\n",
    "y_pos = [1 for i in range(len(positive_sentences))]\n",
    "y_neg = [0 for i in range(len(negative_sentences))]\n",
    "\n",
    "X = positive_sentences + negative_sentences\n",
    "y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c24841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229077\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4113e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train_val = X_train\n",
    "y_train_val = y_train\n",
    "\n",
    "y_train_val_e = to_categorical(y_train_val)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_val_e, test_size=0.2, random_state=1, stratify=y_train_val_e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747457da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632fd6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 228, 300)          68723100  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 228, 600)          540600    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 228, 600)         2400      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 114, 600)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 114, 800)          1440800   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 114, 800)         3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 57, 800)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 57, 1000)          2401000   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 57, 1000)         4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 28, 1000)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 28, 1200)          3601200   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 1200)         4800      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 1200)             0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1200)              1441200   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 600)               720600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 600)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               180300    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,093,502\n",
      "Trainable params: 10,363,202\n",
      "Non-trainable params: 68,730,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.6011\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49953, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 16s 83ms/step - loss: 0.6595 - accuracy: 0.6011 - val_loss: 0.8381 - val_accuracy: 0.4995\n",
      "Epoch 2/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8028\n",
      "Epoch 2: val_accuracy improved from 0.49953 to 0.82625, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 10s 78ms/step - loss: 0.4271 - accuracy: 0.8032 - val_loss: 0.5029 - val_accuracy: 0.8263\n",
      "Epoch 3/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9096\n",
      "Epoch 3: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.2216 - accuracy: 0.9090 - val_loss: 0.4405 - val_accuracy: 0.7658\n",
      "Epoch 4/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9548\n",
      "Epoch 4: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.1216 - accuracy: 0.9549 - val_loss: 13.6852 - val_accuracy: 0.4995\n",
      "Epoch 5/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9785\n",
      "Epoch 5: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0681 - accuracy: 0.9785 - val_loss: 9.6636 - val_accuracy: 0.4995\n",
      "Epoch 6/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9763\n",
      "Epoch 6: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0643 - accuracy: 0.9764 - val_loss: 21.8577 - val_accuracy: 0.4995\n",
      "Epoch 7/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9879\n",
      "Epoch 7: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.6961 - val_accuracy: 0.7894\n",
      "Epoch 8/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9879\n",
      "Epoch 8: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 34.6721 - val_accuracy: 0.5005\n",
      "Epoch 9/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9808\n",
      "Epoch 9: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 71ms/step - loss: 0.0590 - accuracy: 0.9809 - val_loss: 5.2544 - val_accuracy: 0.5042\n",
      "Epoch 10/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9877\n",
      "Epoch 10: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 68ms/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 29.7771 - val_accuracy: 0.4995\n",
      "Epoch 11/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9860\n",
      "Epoch 11: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 10.4524 - val_accuracy: 0.5014\n",
      "Epoch 12/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9936\n",
      "Epoch 12: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 33.6966 - val_accuracy: 0.4995\n",
      "Epoch 13/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9896\n",
      "Epoch 13: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 11.7733 - val_accuracy: 0.5042\n",
      "Epoch 14/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9931\n",
      "Epoch 14: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 18.1563 - val_accuracy: 0.5033\n",
      "Epoch 15/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9922\n",
      "Epoch 15: val_accuracy did not improve from 0.82625\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 22.2912 - val_accuracy: 0.4995\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/133 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9865\n",
      "Epoch 16: val_accuracy improved from 0.82625 to 0.85836, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 10s 79ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.4813 - val_accuracy: 0.8584\n",
      "Epoch 17/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 17: val_accuracy did not improve from 0.85836\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 31.0729 - val_accuracy: 0.5014\n",
      "Epoch 18/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9938\n",
      "Epoch 18: val_accuracy did not improve from 0.85836\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 33.3634 - val_accuracy: 0.4995\n",
      "Epoch 19/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 19: val_accuracy did not improve from 0.85836\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 5.8710 - val_accuracy: 0.5307\n",
      "Epoch 20/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9938\n",
      "Epoch 20: val_accuracy improved from 0.85836 to 0.86686, saving model to .\\model1.h5\n",
      "133/133 [==============================] - 10s 79ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.6349 - val_accuracy: 0.8669\n",
      "Epoch 21/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9927\n",
      "Epoch 21: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 58.2144 - val_accuracy: 0.5005\n",
      "Epoch 22/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9950\n",
      "Epoch 22: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 32.0748 - val_accuracy: 0.4995\n",
      "Epoch 23/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 23: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 71ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.5916 - val_accuracy: 0.8499\n",
      "Epoch 24/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9893\n",
      "Epoch 24: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 71ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 60.6424 - val_accuracy: 0.4995\n",
      "Epoch 25/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 25: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 71ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 43.8471 - val_accuracy: 0.4995\n",
      "Epoch 26/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 26: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 15.1807 - val_accuracy: 0.4995\n",
      "Epoch 27/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 27: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 71ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 49.8187 - val_accuracy: 0.5014\n",
      "Epoch 28/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 28: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 70ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 14.7168 - val_accuracy: 0.5071\n",
      "Epoch 29/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9943\n",
      "Epoch 29: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 9.4679 - val_accuracy: 0.5430\n",
      "Epoch 30/30\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 30: val_accuracy did not improve from 0.86686\n",
      "133/133 [==============================] - 9s 69ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 3.9023 - val_accuracy: 0.5562\n"
     ]
    }
   ],
   "source": [
    "def nlp_cnn(w2v):\n",
    "    inputs = Input(shape=(X_train[0].shape[-1],))\n",
    "\n",
    "    embedding_layer = gensim_to_keras_embedding(w2v)\n",
    "    \n",
    "    embedding_layer = embedding_layer(inputs)\n",
    "\n",
    "    conv = Conv1D(600, 3, padding='same', activation='relu')(embedding_layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(800, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "    \n",
    "    conv = Conv1D(1000, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(1200, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    output = GlobalAveragePooling1D()(conv)\n",
    "\n",
    "    output = Dense(units=1200, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=600, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=300, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=100, activation='relu')(output)\n",
    "    output = Dense(units=2, activation='sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = nlp_cnn(w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('./model1.h5', save_freq=\"epoch\",  verbose=1, monitor='val_accuracy', save_best_only=True,\n",
    "    save_weights_only=False)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd72a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c150a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model1.h5')\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0acf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT OF CNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       661\n",
      "           1       0.91      0.81      0.86       662\n",
      "\n",
      "    accuracy                           0.87      1323\n",
      "   macro avg       0.87      0.87      0.87      1323\n",
      "weighted avg       0.87      0.87      0.87      1323\n",
      "\n",
      "0.8654572940287226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT OF CNN\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e621101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 0\n",
      "embedding 1\n",
      "conv1d 2\n",
      "batch_normalization 3\n",
      "max_pooling1d 4\n",
      "conv1d_1 5\n",
      "batch_normalization_1 6\n",
      "max_pooling1d_1 7\n",
      "conv1d_2 8\n",
      "batch_normalization_2 9\n",
      "max_pooling1d_2 10\n",
      "conv1d_3 11\n",
      "batch_normalization_3 12\n",
      "global_average_pooling1d 13\n",
      "dense 14\n",
      "dropout 15\n",
      "dense_1 16\n",
      "dropout_1 17\n",
      "dense_2 18\n",
      "dropout_2 19\n",
      "dense_3 20\n",
      "dense_4 21\n",
      "166/166 [==============================] - 3s 14ms/step\n",
      "42/42 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(layer.name, i)\n",
    "f = Model(model.input, model.layers[13].output)\n",
    "fe_train_val = f.predict(X_train_val)\n",
    "fe_test = f.predict(X_test)\n",
    "\n",
    "\n",
    "def flatten_features(x):\n",
    "    x_flatten = []\n",
    "    for f in x:\n",
    "        f = f.flatten()\n",
    "        x_flatten.append(f)\n",
    "    x_flatten = np.array(x_flatten)\n",
    "    return x_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0594cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "f_train_val = flatten_features(fe_train_val) # Doesn't put any effect if flatten/global average pooling used\n",
    "f_test = flatten_features(fe_test)\n",
    "\n",
    "# f_train_val = scaler.fit_transform(fe_train_val)\n",
    "# f_test = scaler.fit_transform(fe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80cc4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 1/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 2/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 2/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.960) total time=   0.1s\n",
      "[CV 3/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 3/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.967) total time=   0.1s\n",
      "[CV 4/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 4/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.970) total time=   0.1s\n",
      "[CV 5/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 5/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 1/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 1/5; 2/49] END n_neighbors=2;, score=(train=0.981, test=0.963) total time=   0.1s\n",
      "[CV 2/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 2/5; 2/49] END n_neighbors=2;, score=(train=0.981, test=0.957) total time=   0.1s\n",
      "[CV 3/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 3/5; 2/49] END n_neighbors=2;, score=(train=0.977, test=0.967) total time=   0.1s\n",
      "[CV 4/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 4/5; 2/49] END n_neighbors=2;, score=(train=0.977, test=0.974) total time=   0.1s\n",
      "[CV 5/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 5/5; 2/49] END n_neighbors=2;, score=(train=0.979, test=0.961) total time=   0.1s\n",
      "[CV 1/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 1/5; 3/49] END n_neighbors=3;, score=(train=0.982, test=0.973) total time=   0.1s\n",
      "[CV 2/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 2/5; 3/49] END n_neighbors=3;, score=(train=0.982, test=0.963) total time=   0.1s\n",
      "[CV 3/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 3/5; 3/49] END n_neighbors=3;, score=(train=0.981, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 4/5; 3/49] END n_neighbors=3;, score=(train=0.978, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 5/5; 3/49] END n_neighbors=3;, score=(train=0.979, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 1/5; 4/49] END n_neighbors=4;, score=(train=0.979, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 2/5; 4/49] END n_neighbors=4;, score=(train=0.978, test=0.961) total time=   0.1s\n",
      "[CV 3/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 3/5; 4/49] END n_neighbors=4;, score=(train=0.977, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 4/5; 4/49] END n_neighbors=4;, score=(train=0.975, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 5/5; 4/49] END n_neighbors=4;, score=(train=0.977, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 1/5; 5/49] END n_neighbors=5;, score=(train=0.978, test=0.974) total time=   0.1s\n",
      "[CV 2/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 2/5; 5/49] END n_neighbors=5;, score=(train=0.980, test=0.963) total time=   0.1s\n",
      "[CV 3/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 3/5; 5/49] END n_neighbors=5;, score=(train=0.978, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 4/5; 5/49] END n_neighbors=5;, score=(train=0.976, test=0.983) total time=   0.2s\n",
      "[CV 5/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 5/5; 5/49] END n_neighbors=5;, score=(train=0.978, test=0.975) total time=   0.1s\n",
      "[CV 1/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 1/5; 6/49] END n_neighbors=6;, score=(train=0.976, test=0.972) total time=   0.1s\n",
      "[CV 2/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 2/5; 6/49] END n_neighbors=6;, score=(train=0.978, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 3/5; 6/49] END n_neighbors=6;, score=(train=0.976, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 4/5; 6/49] END n_neighbors=6;, score=(train=0.974, test=0.981) total time=   0.2s\n",
      "[CV 5/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 5/5; 6/49] END n_neighbors=6;, score=(train=0.976, test=0.975) total time=   0.1s\n",
      "[CV 1/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 1/5; 7/49] END n_neighbors=7;, score=(train=0.975, test=0.972) total time=   0.1s\n",
      "[CV 2/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 2/5; 7/49] END n_neighbors=7;, score=(train=0.979, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 3/5; 7/49] END n_neighbors=7;, score=(train=0.976, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 4/5; 7/49] END n_neighbors=7;, score=(train=0.975, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 5/5; 7/49] END n_neighbors=7;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 1/5; 8/49] END n_neighbors=8;, score=(train=0.975, test=0.972) total time=   0.1s\n",
      "[CV 2/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 2/5; 8/49] END n_neighbors=8;, score=(train=0.978, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 3/5; 8/49] END n_neighbors=8;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 4/5; 8/49] END n_neighbors=8;, score=(train=0.974, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 5/5; 8/49] END n_neighbors=8;, score=(train=0.976, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 1/5; 9/49] END n_neighbors=9;, score=(train=0.975, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 2/5; 9/49] END n_neighbors=9;, score=(train=0.978, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 3/5; 9/49] END n_neighbors=9;, score=(train=0.976, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 4/5; 9/49] END n_neighbors=9;, score=(train=0.975, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 5/5; 9/49] END n_neighbors=9;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 1/5; 10/49] END n_neighbors=10;, score=(train=0.975, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 2/5; 10/49] END n_neighbors=10;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 3/5; 10/49] END n_neighbors=10;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 4/5; 10/49] END n_neighbors=10;, score=(train=0.974, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 10/49] START n_neighbors=10............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/49] END n_neighbors=10;, score=(train=0.975, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 1/5; 11/49] END n_neighbors=11;, score=(train=0.975, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 2/5; 11/49] END n_neighbors=11;, score=(train=0.978, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 3/5; 11/49] END n_neighbors=11;, score=(train=0.976, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 4/5; 11/49] END n_neighbors=11;, score=(train=0.974, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 5/5; 11/49] END n_neighbors=11;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 1/5; 12/49] END n_neighbors=12;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 2/5; 12/49] END n_neighbors=12;, score=(train=0.976, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 3/5; 12/49] END n_neighbors=12;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 4/5; 12/49] END n_neighbors=12;, score=(train=0.973, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 5/5; 12/49] END n_neighbors=12;, score=(train=0.974, test=0.974) total time=   0.2s\n",
      "[CV 1/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 1/5; 13/49] END n_neighbors=13;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 2/5; 13/49] END n_neighbors=13;, score=(train=0.977, test=0.967) total time=   0.1s\n",
      "[CV 3/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 3/5; 13/49] END n_neighbors=13;, score=(train=0.975, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 4/5; 13/49] END n_neighbors=13;, score=(train=0.974, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 5/5; 13/49] END n_neighbors=13;, score=(train=0.974, test=0.974) total time=   0.2s\n",
      "[CV 1/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 1/5; 14/49] END n_neighbors=14;, score=(train=0.974, test=0.971) total time=   0.2s\n",
      "[CV 2/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 2/5; 14/49] END n_neighbors=14;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 3/5; 14/49] END n_neighbors=14;, score=(train=0.975, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 4/5; 14/49] END n_neighbors=14;, score=(train=0.973, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 5/5; 14/49] END n_neighbors=14;, score=(train=0.973, test=0.975) total time=   0.1s\n",
      "[CV 1/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 1/5; 15/49] END n_neighbors=15;, score=(train=0.974, test=0.970) total time=   0.2s\n",
      "[CV 2/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 2/5; 15/49] END n_neighbors=15;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 3/5; 15/49] END n_neighbors=15;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 4/5; 15/49] END n_neighbors=15;, score=(train=0.974, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 5/5; 15/49] END n_neighbors=15;, score=(train=0.974, test=0.976) total time=   0.1s\n",
      "[CV 1/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 1/5; 16/49] END n_neighbors=16;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 2/5; 16/49] END n_neighbors=16;, score=(train=0.977, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 3/5; 16/49] END n_neighbors=16;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 4/5; 16/49] END n_neighbors=16;, score=(train=0.973, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 5/5; 16/49] END n_neighbors=16;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 1/5; 17/49] END n_neighbors=17;, score=(train=0.975, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 2/5; 17/49] END n_neighbors=17;, score=(train=0.977, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 3/5; 17/49] END n_neighbors=17;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 4/5; 17/49] END n_neighbors=17;, score=(train=0.973, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 5/5; 17/49] END n_neighbors=17;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 1/5; 18/49] END n_neighbors=18;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 2/5; 18/49] END n_neighbors=18;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 3/5; 18/49] END n_neighbors=18;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 4/5; 18/49] END n_neighbors=18;, score=(train=0.973, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 5/5; 18/49] END n_neighbors=18;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 1/5; 19/49] END n_neighbors=19;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 2/5; 19/49] END n_neighbors=19;, score=(train=0.977, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 3/5; 19/49] END n_neighbors=19;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 4/5; 19/49] END n_neighbors=19;, score=(train=0.973, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 5/5; 19/49] END n_neighbors=19;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 1/5; 20/49] END n_neighbors=20;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 2/5; 20/49] END n_neighbors=20;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 3/5; 20/49] END n_neighbors=20;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 20/49] START n_neighbors=20............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/49] END n_neighbors=20;, score=(train=0.973, test=0.979) total time=   0.1s\n",
      "[CV 5/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 5/5; 20/49] END n_neighbors=20;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 1/5; 21/49] END n_neighbors=21;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 2/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 2/5; 21/49] END n_neighbors=21;, score=(train=0.977, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 3/5; 21/49] END n_neighbors=21;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 4/5; 21/49] END n_neighbors=21;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 5/5; 21/49] END n_neighbors=21;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 1/5; 22/49] END n_neighbors=22;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 2/5; 22/49] END n_neighbors=22;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 3/5; 22/49] END n_neighbors=22;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 4/5; 22/49] END n_neighbors=22;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 5/5; 22/49] END n_neighbors=22;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 1/5; 23/49] END n_neighbors=23;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 2/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 2/5; 23/49] END n_neighbors=23;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 3/5; 23/49] END n_neighbors=23;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 4/5; 23/49] END n_neighbors=23;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 5/5; 23/49] END n_neighbors=23;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 1/5; 24/49] END n_neighbors=24;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 2/5; 24/49] END n_neighbors=24;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 3/5; 24/49] END n_neighbors=24;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 4/5; 24/49] END n_neighbors=24;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 5/5; 24/49] END n_neighbors=24;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 1/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 1/5; 25/49] END n_neighbors=25;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 2/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 2/5; 25/49] END n_neighbors=25;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 3/5; 25/49] END n_neighbors=25;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 4/5; 25/49] END n_neighbors=25;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 5/5; 25/49] END n_neighbors=25;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 1/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 1/5; 26/49] END n_neighbors=26;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 2/5; 26/49] END n_neighbors=26;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 3/5; 26/49] END n_neighbors=26;, score=(train=0.975, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 4/5; 26/49] END n_neighbors=26;, score=(train=0.973, test=0.980) total time=   0.1s\n",
      "[CV 5/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 5/5; 26/49] END n_neighbors=26;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 1/5; 27/49] END n_neighbors=27;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 2/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 2/5; 27/49] END n_neighbors=27;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 3/5; 27/49] END n_neighbors=27;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 4/5; 27/49] END n_neighbors=27;, score=(train=0.972, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 5/5; 27/49] END n_neighbors=27;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 1/5; 28/49] END n_neighbors=28;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 2/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 2/5; 28/49] END n_neighbors=28;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 3/5; 28/49] END n_neighbors=28;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 4/5; 28/49] END n_neighbors=28;, score=(train=0.973, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 5/5; 28/49] END n_neighbors=28;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 1/5; 29/49] END n_neighbors=29;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 2/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 2/5; 29/49] END n_neighbors=29;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 3/5; 29/49] END n_neighbors=29;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 4/5; 29/49] END n_neighbors=29;, score=(train=0.973, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 5/5; 29/49] END n_neighbors=29;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 1/5; 30/49] END n_neighbors=30;, score=(train=0.974, test=0.973) total time=   0.2s\n",
      "[CV 2/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 2/5; 30/49] END n_neighbors=30;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 30/49] START n_neighbors=30............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/49] END n_neighbors=30;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 4/5; 30/49] END n_neighbors=30;, score=(train=0.972, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 5/5; 30/49] END n_neighbors=30;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 1/5; 31/49] END n_neighbors=31;, score=(train=0.975, test=0.973) total time=   0.2s\n",
      "[CV 2/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 2/5; 31/49] END n_neighbors=31;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 3/5; 31/49] END n_neighbors=31;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 4/5; 31/49] END n_neighbors=31;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 5/5; 31/49] END n_neighbors=31;, score=(train=0.974, test=0.975) total time=   0.2s\n",
      "[CV 1/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 1/5; 32/49] END n_neighbors=32;, score=(train=0.975, test=0.973) total time=   0.2s\n",
      "[CV 2/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 2/5; 32/49] END n_neighbors=32;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 3/5; 32/49] END n_neighbors=32;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 4/5; 32/49] END n_neighbors=32;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 5/5; 32/49] END n_neighbors=32;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 1/5; 33/49] END n_neighbors=33;, score=(train=0.975, test=0.973) total time=   0.1s\n",
      "[CV 2/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 2/5; 33/49] END n_neighbors=33;, score=(train=0.977, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 3/5; 33/49] END n_neighbors=33;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 4/5; 33/49] END n_neighbors=33;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 5/5; 33/49] END n_neighbors=33;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 1/5; 34/49] END n_neighbors=34;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 2/5; 34/49] END n_neighbors=34;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 3/5; 34/49] END n_neighbors=34;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 4/5; 34/49] END n_neighbors=34;, score=(train=0.971, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 5/5; 34/49] END n_neighbors=34;, score=(train=0.973, test=0.975) total time=   0.1s\n",
      "[CV 1/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 1/5; 35/49] END n_neighbors=35;, score=(train=0.975, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 2/5; 35/49] END n_neighbors=35;, score=(train=0.977, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 3/5; 35/49] END n_neighbors=35;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 4/5; 35/49] END n_neighbors=35;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 5/5; 35/49] END n_neighbors=35;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 1/5; 36/49] END n_neighbors=36;, score=(train=0.974, test=0.971) total time=   0.1s\n",
      "[CV 2/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 2/5; 36/49] END n_neighbors=36;, score=(train=0.976, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 3/5; 36/49] END n_neighbors=36;, score=(train=0.975, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 4/5; 36/49] END n_neighbors=36;, score=(train=0.971, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 5/5; 36/49] END n_neighbors=36;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 1/5; 37/49] END n_neighbors=37;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 2/5; 37/49] END n_neighbors=37;, score=(train=0.976, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 3/5; 37/49] END n_neighbors=37;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 4/5; 37/49] END n_neighbors=37;, score=(train=0.971, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 5/5; 37/49] END n_neighbors=37;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 1/5; 38/49] END n_neighbors=38;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 2/5; 38/49] END n_neighbors=38;, score=(train=0.976, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 3/5; 38/49] END n_neighbors=38;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 4/5; 38/49] END n_neighbors=38;, score=(train=0.970, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 5/5; 38/49] END n_neighbors=38;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 1/5; 39/49] END n_neighbors=39;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 2/5; 39/49] END n_neighbors=39;, score=(train=0.977, test=0.964) total time=   0.1s\n",
      "[CV 3/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 3/5; 39/49] END n_neighbors=39;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 4/5; 39/49] END n_neighbors=39;, score=(train=0.970, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 5/5; 39/49] END n_neighbors=39;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 1/5; 40/49] END n_neighbors=40;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 40/49] START n_neighbors=40............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/49] END n_neighbors=40;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 3/5; 40/49] END n_neighbors=40;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 4/5; 40/49] END n_neighbors=40;, score=(train=0.970, test=0.981) total time=   0.1s\n",
      "[CV 5/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 5/5; 40/49] END n_neighbors=40;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 1/5; 41/49] END n_neighbors=41;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 2/5; 41/49] END n_neighbors=41;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 3/5; 41/49] END n_neighbors=41;, score=(train=0.974, test=0.974) total time=   0.1s\n",
      "[CV 4/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 4/5; 41/49] END n_neighbors=41;, score=(train=0.970, test=0.982) total time=   0.2s\n",
      "[CV 5/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 5/5; 41/49] END n_neighbors=41;, score=(train=0.973, test=0.972) total time=   0.1s\n",
      "[CV 1/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 1/5; 42/49] END n_neighbors=42;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 2/5; 42/49] END n_neighbors=42;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 3/5; 42/49] END n_neighbors=42;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 4/5; 42/49] END n_neighbors=42;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 5/5; 42/49] END n_neighbors=42;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 1/5; 43/49] END n_neighbors=43;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 2/5; 43/49] END n_neighbors=43;, score=(train=0.976, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 3/5; 43/49] END n_neighbors=43;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 4/5; 43/49] END n_neighbors=43;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 5/5; 43/49] END n_neighbors=43;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 1/5; 44/49] END n_neighbors=44;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 2/5; 44/49] END n_neighbors=44;, score=(train=0.975, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 3/5; 44/49] END n_neighbors=44;, score=(train=0.975, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 4/5; 44/49] END n_neighbors=44;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 5/5; 44/49] END n_neighbors=44;, score=(train=0.973, test=0.973) total time=   0.1s\n",
      "[CV 1/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 1/5; 45/49] END n_neighbors=45;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 2/5; 45/49] END n_neighbors=45;, score=(train=0.975, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 3/5; 45/49] END n_neighbors=45;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 4/5; 45/49] END n_neighbors=45;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 5/5; 45/49] END n_neighbors=45;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 1/5; 46/49] END n_neighbors=46;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 2/5; 46/49] END n_neighbors=46;, score=(train=0.975, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 3/5; 46/49] END n_neighbors=46;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 4/5; 46/49] END n_neighbors=46;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 5/5; 46/49] END n_neighbors=46;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 1/5; 47/49] END n_neighbors=47;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 2/5; 47/49] END n_neighbors=47;, score=(train=0.975, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 3/5; 47/49] END n_neighbors=47;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 4/5; 47/49] END n_neighbors=47;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 5/5; 47/49] END n_neighbors=47;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 1/5; 48/49] END n_neighbors=48;, score=(train=0.974, test=0.969) total time=   0.1s\n",
      "[CV 2/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 2/5; 48/49] END n_neighbors=48;, score=(train=0.975, test=0.966) total time=   0.1s\n",
      "[CV 3/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 3/5; 48/49] END n_neighbors=48;, score=(train=0.974, test=0.972) total time=   0.1s\n",
      "[CV 4/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 4/5; 48/49] END n_neighbors=48;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 5/5; 48/49] END n_neighbors=48;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "[CV 1/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 1/5; 49/49] END n_neighbors=49;, score=(train=0.974, test=0.970) total time=   0.1s\n",
      "[CV 2/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 2/5; 49/49] END n_neighbors=49;, score=(train=0.976, test=0.965) total time=   0.1s\n",
      "[CV 3/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 3/5; 49/49] END n_neighbors=49;, score=(train=0.974, test=0.973) total time=   0.1s\n",
      "[CV 4/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 4/5; 49/49] END n_neighbors=49;, score=(train=0.971, test=0.982) total time=   0.1s\n",
      "[CV 5/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 5/5; 49/49] END n_neighbors=49;, score=(train=0.973, test=0.974) total time=   0.1s\n",
      "{'n_neighbors': 31}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 50))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=True,verbose=10)\n",
    "grid_search=grid.fit(f_train_val, y_train_val)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f4fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighbors = []\n",
    "l = []\n",
    "for i, p in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    neighbors.append({'neighbor': i+1, 'score': p})\n",
    "    l.append(i+1)\n",
    "\n",
    "neighbors.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(l,grid.cv_results_['mean_test_score'])\n",
    "ax.set_ylim([0.95, 0.98])\n",
    "plt.title('GridSearchCV Results')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Nearest Neighbor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9afbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       661\n",
      "           1       0.90      0.83      0.87       662\n",
      "\n",
      "    accuracy                           0.87      1323\n",
      "   macro avg       0.87      0.87      0.87      1323\n",
      "weighted avg       0.87      0.87      0.87      1323\n",
      "\n",
      "KNN 0.8707482993197279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "knn.fit(f_train_val, y_train_val)\n",
    "preds = knn.predict(f_test)\n",
    "preds_proba = knn.predict_proba(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14510656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=neighbors[1]['neighbor'])\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=neighbors[2]['neighbor'])\n",
    "\n",
    "knn4 = KNeighborsClassifier(n_neighbors=neighbors[3]['neighbor'])\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=neighbors[4]['neighbor'])\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('knn1', knn1),\n",
    "                                     ('knn2', knn2),\n",
    "                                    ('knn3', knn3),\n",
    "                                     ('knn4', knn4),\n",
    "                                     ('knn5', knn5),\n",
    "                                    ], voting='soft')\n",
    "\n",
    "eclf1.fit(f_train_val, y_train_val)\n",
    "\n",
    "preds = eclf1.predict(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f11ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       661\n",
      "           1       0.91      0.84      0.87       662\n",
      "\n",
      "    accuracy                           0.88      1323\n",
      "   macro avg       0.88      0.88      0.88      1323\n",
      "weighted avg       0.88      0.88      0.88      1323\n",
      "\n",
      "KNN VOTING 0.8767951625094482\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN VOTING\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe0c01c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       661\n",
      "           1       0.89      0.86      0.87       662\n",
      "\n",
      "    accuracy                           0.88      1323\n",
      "   macro avg       0.88      0.88      0.88      1323\n",
      "weighted avg       0.88      0.88      0.88      1323\n",
      "\n",
      "SVM  0.8752834467120182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly')\n",
    "svclassifier.fit(f_train_val, y_train_val)\n",
    "preds = svclassifier.predict(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"SVM \", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f1992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb132767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
