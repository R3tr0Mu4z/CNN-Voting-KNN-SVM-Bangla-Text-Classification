{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f933f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Dataset (Bangla Online Comments Dataset) : https://data.mendeley.com/datasets/9xjx8twk8p/1\n",
    "\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8966bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['not bully', 'religious', 'sexual', 'threat', 'troll'], dtype='<U9'), array([15340,  7577,  8928,  1694, 10462], dtype=int64))\n",
      "19733 bully\n",
      "15340 not_bully\n",
      "After Balancing\n",
      "15340 bully\n",
      "15340 not_bully\n"
     ]
    }
   ],
   "source": [
    "# Loading Bangla Online Comments Dataset\n",
    "bully = []\n",
    "not_bully = []\n",
    "\n",
    "\n",
    "df = pd.read_excel('../datasets/bangla_online_comments_dataset.xlsx')\n",
    "\n",
    "labels = np.array(df['label'].tolist())\n",
    "print(np.unique(labels, return_counts=True))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == 'not bully':\n",
    "        not_bully.append(row['comment'])\n",
    "    elif row['label'] != 'sexual':\n",
    "        bully.append(row['comment'])\n",
    "    \n",
    "print(len(bully), 'bully')\n",
    "print(len(not_bully), 'not_bully')\n",
    "\n",
    "import random\n",
    "random.shuffle(bully)\n",
    "\n",
    "for i in range(len(bully)-len(not_bully)):\n",
    "    bully.pop(0)\n",
    "\n",
    "print(\"After Balancing\")\n",
    "print(len(bully), 'bully')\n",
    "print(len(not_bully), 'not_bully')\n",
    "\n",
    "\n",
    "y_pos = [1 for i in range(len(not_bully))]\n",
    "y_neg = [0 for i in range(len(bully))]\n",
    "\n",
    "X = not_bully + bully\n",
    "y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c24841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229077\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "words = list(w2v_model.wv.index_to_key)\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4113e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "X_train_val = X_train\n",
    "y_train_val = y_train\n",
    "\n",
    "y_train_val_e = to_categorical(y_train_val)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_val_e, test_size=0.2, random_state=1, stratify=y_train_val_e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747457da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632fd6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 300)          68723100  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 200, 600)          540600    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 200, 600)         2400      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 100, 600)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 100, 800)          1440800   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100, 800)         3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 50, 800)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 50, 1000)          2401000   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 50, 1000)         4000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 25, 1000)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 25, 1200)          3601200   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 1200)         4800      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 1200)             0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1200)              1441200   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 600)               720600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 600)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               180300    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,093,502\n",
      "Trainable params: 10,363,202\n",
      "Non-trainable params: 68,730,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.6971\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50051, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 46s 67ms/step - loss: 0.5665 - accuracy: 0.6971 - val_loss: 1.9908 - val_accuracy: 0.5005\n",
      "Epoch 2/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.3939 - accuracy: 0.8198\n",
      "Epoch 2: val_accuracy did not improve from 0.50051\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.3939 - accuracy: 0.8198 - val_loss: 6.6920 - val_accuracy: 0.5003\n",
      "Epoch 3/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.8748\n",
      "Epoch 3: val_accuracy improved from 0.50051 to 0.65594, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.2949 - accuracy: 0.8748 - val_loss: 0.7104 - val_accuracy: 0.6559\n",
      "Epoch 4/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9175\n",
      "Epoch 4: val_accuracy did not improve from 0.65594\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.2026 - accuracy: 0.9175 - val_loss: 1.0471 - val_accuracy: 0.5083\n",
      "Epoch 5/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9423\n",
      "Epoch 5: val_accuracy did not improve from 0.65594\n",
      "614/614 [==============================] - 40s 65ms/step - loss: 0.1470 - accuracy: 0.9423 - val_loss: 2.9036 - val_accuracy: 0.5038\n",
      "Epoch 6/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9576\n",
      "Epoch 6: val_accuracy improved from 0.65594 to 0.68670, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.1124 - accuracy: 0.9575 - val_loss: 0.5591 - val_accuracy: 0.6867\n",
      "Epoch 7/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9654\n",
      "Epoch 7: val_accuracy did not improve from 0.68670\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0914 - accuracy: 0.9654 - val_loss: 7.9321 - val_accuracy: 0.5435\n",
      "Epoch 8/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9677\n",
      "Epoch 8: val_accuracy did not improve from 0.68670\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0819 - accuracy: 0.9678 - val_loss: 3.0754 - val_accuracy: 0.6162\n",
      "Epoch 9/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9702\n",
      "Epoch 9: val_accuracy did not improve from 0.68670\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 2.5185 - val_accuracy: 0.5563\n",
      "Epoch 10/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9731\n",
      "Epoch 10: val_accuracy did not improve from 0.68670\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0714 - accuracy: 0.9730 - val_loss: 4.4209 - val_accuracy: 0.5003\n",
      "Epoch 11/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9750\n",
      "Epoch 11: val_accuracy did not improve from 0.68670\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0639 - accuracy: 0.9749 - val_loss: 5.1475 - val_accuracy: 0.5635\n",
      "Epoch 12/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9772\n",
      "Epoch 12: val_accuracy improved from 0.68670 to 0.70707, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.0587 - accuracy: 0.9771 - val_loss: 1.2275 - val_accuracy: 0.7071\n",
      "Epoch 13/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9763\n",
      "Epoch 13: val_accuracy did not improve from 0.70707\n",
      "614/614 [==============================] - 41s 67ms/step - loss: 0.0604 - accuracy: 0.9763 - val_loss: 1.8538 - val_accuracy: 0.5219\n",
      "Epoch 14/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9778\n",
      "Epoch 14: val_accuracy did not improve from 0.70707\n",
      "614/614 [==============================] - 42s 68ms/step - loss: 0.0557 - accuracy: 0.9777 - val_loss: 0.8783 - val_accuracy: 0.6327\n",
      "Epoch 15/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9786\n",
      "Epoch 15: val_accuracy did not improve from 0.70707\n",
      "614/614 [==============================] - 40s 65ms/step - loss: 0.0569 - accuracy: 0.9786 - val_loss: 2.9477 - val_accuracy: 0.5007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9811\n",
      "Epoch 16: val_accuracy did not improve from 0.70707\n",
      "614/614 [==============================] - 41s 67ms/step - loss: 0.0517 - accuracy: 0.9812 - val_loss: 7.7200 - val_accuracy: 0.5402\n",
      "Epoch 17/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9820\n",
      "Epoch 17: val_accuracy did not improve from 0.70707\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 16.8395 - val_accuracy: 0.5009\n",
      "Epoch 18/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9807\n",
      "Epoch 18: val_accuracy improved from 0.70707 to 0.75535, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 41s 67ms/step - loss: 0.0491 - accuracy: 0.9807 - val_loss: 1.6107 - val_accuracy: 0.7553\n",
      "Epoch 19/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9825\n",
      "Epoch 19: val_accuracy did not improve from 0.75535\n",
      "614/614 [==============================] - 41s 67ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 17.4106 - val_accuracy: 0.5009\n",
      "Epoch 20/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9811\n",
      "Epoch 20: val_accuracy did not improve from 0.75535\n",
      "614/614 [==============================] - 40s 65ms/step - loss: 0.0469 - accuracy: 0.9812 - val_loss: 4.4650 - val_accuracy: 0.5303\n",
      "Epoch 21/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9841\n",
      "Epoch 21: val_accuracy improved from 0.75535 to 0.78040, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 43s 70ms/step - loss: 0.0443 - accuracy: 0.9841 - val_loss: 0.7056 - val_accuracy: 0.7804\n",
      "Epoch 22/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9851\n",
      "Epoch 22: val_accuracy did not improve from 0.78040\n",
      "614/614 [==============================] - 40s 65ms/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.6777 - val_accuracy: 0.6423\n",
      "Epoch 23/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9837\n",
      "Epoch 23: val_accuracy did not improve from 0.78040\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.0419 - accuracy: 0.9837 - val_loss: 4.1864 - val_accuracy: 0.5036\n",
      "Epoch 24/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9840\n",
      "Epoch 24: val_accuracy did not improve from 0.78040\n",
      "614/614 [==============================] - 40s 66ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 0.9113 - val_accuracy: 0.7179\n",
      "Epoch 25/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9858\n",
      "Epoch 25: val_accuracy improved from 0.78040 to 0.79527, saving model to .\\model2.h5\n",
      "614/614 [==============================] - 41s 66ms/step - loss: 0.0385 - accuracy: 0.9858 - val_loss: 1.0901 - val_accuracy: 0.7953\n",
      "Epoch 26/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9839\n",
      "Epoch 26: val_accuracy did not improve from 0.79527\n",
      "614/614 [==============================] - 39s 63ms/step - loss: 0.0420 - accuracy: 0.9839 - val_loss: 1.5461 - val_accuracy: 0.6260\n",
      "Epoch 27/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9841\n",
      "Epoch 27: val_accuracy did not improve from 0.79527\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0396 - accuracy: 0.9842 - val_loss: 4.7944 - val_accuracy: 0.5019\n",
      "Epoch 28/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9856\n",
      "Epoch 28: val_accuracy did not improve from 0.79527\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0345 - accuracy: 0.9856 - val_loss: 1.4928 - val_accuracy: 0.7794\n",
      "Epoch 29/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9859\n",
      "Epoch 29: val_accuracy did not improve from 0.79527\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0342 - accuracy: 0.9859 - val_loss: 3.7344 - val_accuracy: 0.5015\n",
      "Epoch 30/30\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9864\n",
      "Epoch 30: val_accuracy did not improve from 0.79527\n",
      "614/614 [==============================] - 39s 64ms/step - loss: 0.0362 - accuracy: 0.9864 - val_loss: 11.0729 - val_accuracy: 0.5007\n"
     ]
    }
   ],
   "source": [
    "def nlp_cnn(w2v):\n",
    "    inputs = Input(shape=(X_train[0].shape[-1],))\n",
    "\n",
    "    embedding_layer = gensim_to_keras_embedding(w2v)\n",
    "    \n",
    "    embedding_layer = embedding_layer(inputs)\n",
    "\n",
    "    conv = Conv1D(600, 3, padding='same', activation='relu')(embedding_layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(800, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "    \n",
    "    conv = Conv1D(1000, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = MaxPool1D(pool_size=(2))(conv)\n",
    "\n",
    "    conv = Conv1D(1200, 3, padding='same', activation='relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    output = GlobalAveragePooling1D()(conv)\n",
    "\n",
    "    output = Dense(units=1200, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=600, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=300, activation='relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units=100, activation='relu')(output)\n",
    "    output = Dense(units=2, activation='sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = nlp_cnn(w2v_model)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('./model2.h5', save_freq=\"epoch\",  verbose=1, monitor='val_accuracy', save_best_only=True,\n",
    "    save_weights_only=False)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "optimizer = Adam(0.0001)\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd72a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c150a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 3s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Taking the last layer predictions\n",
    "model = load_model('./model2.h5')\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0acf366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT OF CNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      3068\n",
      "           1       0.77      0.85      0.81      3068\n",
      "\n",
      "    accuracy                           0.80      6136\n",
      "   macro avg       0.80      0.80      0.80      6136\n",
      "weighted avg       0.80      0.80      0.80      6136\n",
      "\n",
      "0.796284224250326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT OF CNN\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e621101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 0\n",
      "embedding 1\n",
      "conv1d 2\n",
      "batch_normalization 3\n",
      "max_pooling1d 4\n",
      "conv1d_1 5\n",
      "batch_normalization_1 6\n",
      "max_pooling1d_1 7\n",
      "conv1d_2 8\n",
      "batch_normalization_2 9\n",
      "max_pooling1d_2 10\n",
      "conv1d_3 11\n",
      "batch_normalization_3 12\n",
      "global_average_pooling1d 13\n",
      "dense 14\n",
      "dropout 15\n",
      "dense_1 16\n",
      "dropout_1 17\n",
      "dense_2 18\n",
      "dropout_2 19\n",
      "dense_3 20\n",
      "dense_4 21\n",
      "767/767 [==============================] - 10s 13ms/step\n",
      "192/192 [==============================] - 3s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(layer.name, i)\n",
    "f = Model(model.input, model.layers[13].output)\n",
    "fe_train_val = f.predict(X_train_val)\n",
    "fe_test = f.predict(X_test)\n",
    "\n",
    "\n",
    "def flatten_features(x):\n",
    "    x_flatten = []\n",
    "    for f in x:\n",
    "        f = f.flatten()\n",
    "        x_flatten.append(f)\n",
    "    x_flatten = np.array(x_flatten)\n",
    "    return x_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae485b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "f_train_val = flatten_features(fe_train_val)\n",
    "f_test = flatten_features(fe_test)\n",
    "\n",
    "# f_train_val = scaler.fit_transform(fe_train_val)\n",
    "# f_test = scaler.fit_transform(fe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b97e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 1/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.919) total time=   0.1s\n",
      "[CV 2/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 2/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.938) total time=   0.0s\n",
      "[CV 3/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 3/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.916) total time=   0.0s\n",
      "[CV 4/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 4/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.925) total time=   0.1s\n",
      "[CV 5/5; 1/49] START n_neighbors=1..............................................\n",
      "[CV 5/5; 1/49] END n_neighbors=1;, score=(train=1.000, test=0.926) total time=   0.0s\n",
      "[CV 1/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 1/5; 2/49] END n_neighbors=2;, score=(train=0.967, test=0.921) total time=   0.1s\n",
      "[CV 2/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 2/5; 2/49] END n_neighbors=2;, score=(train=0.961, test=0.940) total time=   0.1s\n",
      "[CV 3/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 3/5; 2/49] END n_neighbors=2;, score=(train=0.963, test=0.916) total time=   0.1s\n",
      "[CV 4/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 4/5; 2/49] END n_neighbors=2;, score=(train=0.962, test=0.913) total time=   0.1s\n",
      "[CV 5/5; 2/49] START n_neighbors=2..............................................\n",
      "[CV 5/5; 2/49] END n_neighbors=2;, score=(train=0.964, test=0.914) total time=   0.1s\n",
      "[CV 1/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 1/5; 3/49] END n_neighbors=3;, score=(train=0.965, test=0.941) total time=   0.1s\n",
      "[CV 2/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 2/5; 3/49] END n_neighbors=3;, score=(train=0.963, test=0.953) total time=   0.1s\n",
      "[CV 3/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 3/5; 3/49] END n_neighbors=3;, score=(train=0.966, test=0.944) total time=   0.1s\n",
      "[CV 4/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 4/5; 3/49] END n_neighbors=3;, score=(train=0.965, test=0.936) total time=   0.1s\n",
      "[CV 5/5; 3/49] START n_neighbors=3..............................................\n",
      "[CV 5/5; 3/49] END n_neighbors=3;, score=(train=0.968, test=0.941) total time=   0.1s\n",
      "[CV 1/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 1/5; 4/49] END n_neighbors=4;, score=(train=0.960, test=0.942) total time=   0.1s\n",
      "[CV 2/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 2/5; 4/49] END n_neighbors=4;, score=(train=0.962, test=0.949) total time=   0.1s\n",
      "[CV 3/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 3/5; 4/49] END n_neighbors=4;, score=(train=0.960, test=0.942) total time=   0.1s\n",
      "[CV 4/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 4/5; 4/49] END n_neighbors=4;, score=(train=0.959, test=0.945) total time=   0.1s\n",
      "[CV 5/5; 4/49] START n_neighbors=4..............................................\n",
      "[CV 5/5; 4/49] END n_neighbors=4;, score=(train=0.961, test=0.941) total time=   0.1s\n",
      "[CV 1/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 1/5; 5/49] END n_neighbors=5;, score=(train=0.959, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 2/5; 5/49] END n_neighbors=5;, score=(train=0.960, test=0.952) total time=   0.1s\n",
      "[CV 3/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 3/5; 5/49] END n_neighbors=5;, score=(train=0.959, test=0.946) total time=   0.1s\n",
      "[CV 4/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 4/5; 5/49] END n_neighbors=5;, score=(train=0.959, test=0.944) total time=   0.1s\n",
      "[CV 5/5; 5/49] START n_neighbors=5..............................................\n",
      "[CV 5/5; 5/49] END n_neighbors=5;, score=(train=0.961, test=0.949) total time=   0.1s\n",
      "[CV 1/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 1/5; 6/49] END n_neighbors=6;, score=(train=0.957, test=0.947) total time=   0.1s\n",
      "[CV 2/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 2/5; 6/49] END n_neighbors=6;, score=(train=0.956, test=0.949) total time=   0.1s\n",
      "[CV 3/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 3/5; 6/49] END n_neighbors=6;, score=(train=0.956, test=0.944) total time=   0.1s\n",
      "[CV 4/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 4/5; 6/49] END n_neighbors=6;, score=(train=0.958, test=0.946) total time=   0.1s\n",
      "[CV 5/5; 6/49] START n_neighbors=6..............................................\n",
      "[CV 5/5; 6/49] END n_neighbors=6;, score=(train=0.956, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 1/5; 7/49] END n_neighbors=7;, score=(train=0.958, test=0.947) total time=   0.1s\n",
      "[CV 2/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 2/5; 7/49] END n_neighbors=7;, score=(train=0.956, test=0.953) total time=   0.1s\n",
      "[CV 3/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 3/5; 7/49] END n_neighbors=7;, score=(train=0.956, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 4/5; 7/49] END n_neighbors=7;, score=(train=0.957, test=0.947) total time=   0.1s\n",
      "[CV 5/5; 7/49] START n_neighbors=7..............................................\n",
      "[CV 5/5; 7/49] END n_neighbors=7;, score=(train=0.957, test=0.950) total time=   0.1s\n",
      "[CV 1/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 1/5; 8/49] END n_neighbors=8;, score=(train=0.956, test=0.946) total time=   0.1s\n",
      "[CV 2/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 2/5; 8/49] END n_neighbors=8;, score=(train=0.954, test=0.954) total time=   0.1s\n",
      "[CV 3/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 3/5; 8/49] END n_neighbors=8;, score=(train=0.956, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 4/5; 8/49] END n_neighbors=8;, score=(train=0.956, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 8/49] START n_neighbors=8..............................................\n",
      "[CV 5/5; 8/49] END n_neighbors=8;, score=(train=0.957, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 1/5; 9/49] END n_neighbors=9;, score=(train=0.955, test=0.946) total time=   0.1s\n",
      "[CV 2/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 2/5; 9/49] END n_neighbors=9;, score=(train=0.955, test=0.953) total time=   0.1s\n",
      "[CV 3/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 3/5; 9/49] END n_neighbors=9;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 4/5; 9/49] END n_neighbors=9;, score=(train=0.955, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 9/49] START n_neighbors=9..............................................\n",
      "[CV 5/5; 9/49] END n_neighbors=9;, score=(train=0.957, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 1/5; 10/49] END n_neighbors=10;, score=(train=0.955, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 2/5; 10/49] END n_neighbors=10;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 3/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 3/5; 10/49] END n_neighbors=10;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 10/49] START n_neighbors=10............................................\n",
      "[CV 4/5; 10/49] END n_neighbors=10;, score=(train=0.955, test=0.948) total time=   0.1s\n",
      "[CV 5/5; 10/49] START n_neighbors=10............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/49] END n_neighbors=10;, score=(train=0.957, test=0.954) total time=   0.1s\n",
      "[CV 1/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 1/5; 11/49] END n_neighbors=11;, score=(train=0.955, test=0.947) total time=   0.1s\n",
      "[CV 2/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 2/5; 11/49] END n_neighbors=11;, score=(train=0.955, test=0.954) total time=   0.1s\n",
      "[CV 3/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 3/5; 11/49] END n_neighbors=11;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 4/5; 11/49] END n_neighbors=11;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 11/49] START n_neighbors=11............................................\n",
      "[CV 5/5; 11/49] END n_neighbors=11;, score=(train=0.956, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 1/5; 12/49] END n_neighbors=12;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 2/5; 12/49] END n_neighbors=12;, score=(train=0.955, test=0.955) total time=   0.1s\n",
      "[CV 3/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 3/5; 12/49] END n_neighbors=12;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 4/5; 12/49] END n_neighbors=12;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 12/49] START n_neighbors=12............................................\n",
      "[CV 5/5; 12/49] END n_neighbors=12;, score=(train=0.956, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 1/5; 13/49] END n_neighbors=13;, score=(train=0.955, test=0.948) total time=   0.1s\n",
      "[CV 2/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 2/5; 13/49] END n_neighbors=13;, score=(train=0.955, test=0.954) total time=   0.1s\n",
      "[CV 3/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 3/5; 13/49] END n_neighbors=13;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 4/5; 13/49] END n_neighbors=13;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 13/49] START n_neighbors=13............................................\n",
      "[CV 5/5; 13/49] END n_neighbors=13;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 1/5; 14/49] END n_neighbors=14;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 2/5; 14/49] END n_neighbors=14;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 3/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 3/5; 14/49] END n_neighbors=14;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 4/5; 14/49] END n_neighbors=14;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 14/49] START n_neighbors=14............................................\n",
      "[CV 5/5; 14/49] END n_neighbors=14;, score=(train=0.955, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 1/5; 15/49] END n_neighbors=15;, score=(train=0.955, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 2/5; 15/49] END n_neighbors=15;, score=(train=0.954, test=0.956) total time=   0.1s\n",
      "[CV 3/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 3/5; 15/49] END n_neighbors=15;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 4/5; 15/49] END n_neighbors=15;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 15/49] START n_neighbors=15............................................\n",
      "[CV 5/5; 15/49] END n_neighbors=15;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 1/5; 16/49] END n_neighbors=16;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 2/5; 16/49] END n_neighbors=16;, score=(train=0.955, test=0.955) total time=   0.1s\n",
      "[CV 3/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 3/5; 16/49] END n_neighbors=16;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 4/5; 16/49] END n_neighbors=16;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 16/49] START n_neighbors=16............................................\n",
      "[CV 5/5; 16/49] END n_neighbors=16;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 1/5; 17/49] END n_neighbors=17;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 2/5; 17/49] END n_neighbors=17;, score=(train=0.954, test=0.957) total time=   0.1s\n",
      "[CV 3/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 3/5; 17/49] END n_neighbors=17;, score=(train=0.955, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 4/5; 17/49] END n_neighbors=17;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 17/49] START n_neighbors=17............................................\n",
      "[CV 5/5; 17/49] END n_neighbors=17;, score=(train=0.953, test=0.954) total time=   0.1s\n",
      "[CV 1/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 1/5; 18/49] END n_neighbors=18;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 2/5; 18/49] END n_neighbors=18;, score=(train=0.953, test=0.955) total time=   0.1s\n",
      "[CV 3/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 3/5; 18/49] END n_neighbors=18;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 4/5; 18/49] END n_neighbors=18;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 18/49] START n_neighbors=18............................................\n",
      "[CV 5/5; 18/49] END n_neighbors=18;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 1/5; 19/49] END n_neighbors=19;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 2/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 2/5; 19/49] END n_neighbors=19;, score=(train=0.953, test=0.956) total time=   0.1s\n",
      "[CV 3/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 3/5; 19/49] END n_neighbors=19;, score=(train=0.955, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 4/5; 19/49] END n_neighbors=19;, score=(train=0.954, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 19/49] START n_neighbors=19............................................\n",
      "[CV 5/5; 19/49] END n_neighbors=19;, score=(train=0.954, test=0.951) total time=   0.2s\n",
      "[CV 1/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 1/5; 20/49] END n_neighbors=20;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 2/5; 20/49] END n_neighbors=20;, score=(train=0.953, test=0.956) total time=   0.1s\n",
      "[CV 3/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 3/5; 20/49] END n_neighbors=20;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 20/49] START n_neighbors=20............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/49] END n_neighbors=20;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 20/49] START n_neighbors=20............................................\n",
      "[CV 5/5; 20/49] END n_neighbors=20;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 1/5; 21/49] END n_neighbors=21;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 2/5; 21/49] END n_neighbors=21;, score=(train=0.952, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 3/5; 21/49] END n_neighbors=21;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 4/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 4/5; 21/49] END n_neighbors=21;, score=(train=0.955, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 21/49] START n_neighbors=21............................................\n",
      "[CV 5/5; 21/49] END n_neighbors=21;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 1/5; 22/49] END n_neighbors=22;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 2/5; 22/49] END n_neighbors=22;, score=(train=0.953, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 3/5; 22/49] END n_neighbors=22;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 4/5; 22/49] END n_neighbors=22;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 22/49] START n_neighbors=22............................................\n",
      "[CV 5/5; 22/49] END n_neighbors=22;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 1/5; 23/49] END n_neighbors=23;, score=(train=0.954, test=0.952) total time=   0.1s\n",
      "[CV 2/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 2/5; 23/49] END n_neighbors=23;, score=(train=0.953, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 3/5; 23/49] END n_neighbors=23;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 4/5; 23/49] END n_neighbors=23;, score=(train=0.954, test=0.952) total time=   0.1s\n",
      "[CV 5/5; 23/49] START n_neighbors=23............................................\n",
      "[CV 5/5; 23/49] END n_neighbors=23;, score=(train=0.954, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 1/5; 24/49] END n_neighbors=24;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 2/5; 24/49] END n_neighbors=24;, score=(train=0.953, test=0.959) total time=   0.1s\n",
      "[CV 3/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 3/5; 24/49] END n_neighbors=24;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 4/5; 24/49] END n_neighbors=24;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 24/49] START n_neighbors=24............................................\n",
      "[CV 5/5; 24/49] END n_neighbors=24;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 1/5; 25/49] END n_neighbors=25;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 2/5; 25/49] END n_neighbors=25;, score=(train=0.953, test=0.959) total time=   0.1s\n",
      "[CV 3/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 3/5; 25/49] END n_neighbors=25;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 4/5; 25/49] END n_neighbors=25;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 25/49] START n_neighbors=25............................................\n",
      "[CV 5/5; 25/49] END n_neighbors=25;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 1/5; 26/49] END n_neighbors=26;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 2/5; 26/49] END n_neighbors=26;, score=(train=0.952, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 3/5; 26/49] END n_neighbors=26;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 4/5; 26/49] END n_neighbors=26;, score=(train=0.955, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 26/49] START n_neighbors=26............................................\n",
      "[CV 5/5; 26/49] END n_neighbors=26;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 1/5; 27/49] END n_neighbors=27;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 2/5; 27/49] END n_neighbors=27;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 3/5; 27/49] END n_neighbors=27;, score=(train=0.954, test=0.947) total time=   0.1s\n",
      "[CV 4/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 4/5; 27/49] END n_neighbors=27;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 27/49] START n_neighbors=27............................................\n",
      "[CV 5/5; 27/49] END n_neighbors=27;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 1/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 1/5; 28/49] END n_neighbors=28;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 2/5; 28/49] END n_neighbors=28;, score=(train=0.952, test=0.960) total time=   0.1s\n",
      "[CV 3/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 3/5; 28/49] END n_neighbors=28;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 4/5; 28/49] END n_neighbors=28;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 28/49] START n_neighbors=28............................................\n",
      "[CV 5/5; 28/49] END n_neighbors=28;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 1/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 1/5; 29/49] END n_neighbors=29;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 2/5; 29/49] END n_neighbors=29;, score=(train=0.952, test=0.959) total time=   0.1s\n",
      "[CV 3/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 3/5; 29/49] END n_neighbors=29;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 4/5; 29/49] END n_neighbors=29;, score=(train=0.955, test=0.953) total time=   0.1s\n",
      "[CV 5/5; 29/49] START n_neighbors=29............................................\n",
      "[CV 5/5; 29/49] END n_neighbors=29;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 1/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 1/5; 30/49] END n_neighbors=30;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 2/5; 30/49] END n_neighbors=30;, score=(train=0.951, test=0.960) total time=   0.1s\n",
      "[CV 3/5; 30/49] START n_neighbors=30............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/49] END n_neighbors=30;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 4/5; 30/49] END n_neighbors=30;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 30/49] START n_neighbors=30............................................\n",
      "[CV 5/5; 30/49] END n_neighbors=30;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 1/5; 31/49] END n_neighbors=31;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 2/5; 31/49] END n_neighbors=31;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 3/5; 31/49] END n_neighbors=31;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 4/5; 31/49] END n_neighbors=31;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 31/49] START n_neighbors=31............................................\n",
      "[CV 5/5; 31/49] END n_neighbors=31;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 1/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 1/5; 32/49] END n_neighbors=32;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 2/5; 32/49] END n_neighbors=32;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 3/5; 32/49] END n_neighbors=32;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 4/5; 32/49] END n_neighbors=32;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 32/49] START n_neighbors=32............................................\n",
      "[CV 5/5; 32/49] END n_neighbors=32;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 1/5; 33/49] END n_neighbors=33;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 2/5; 33/49] END n_neighbors=33;, score=(train=0.952, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 3/5; 33/49] END n_neighbors=33;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 4/5; 33/49] END n_neighbors=33;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 33/49] START n_neighbors=33............................................\n",
      "[CV 5/5; 33/49] END n_neighbors=33;, score=(train=0.953, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 1/5; 34/49] END n_neighbors=34;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 2/5; 34/49] END n_neighbors=34;, score=(train=0.952, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 3/5; 34/49] END n_neighbors=34;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 4/5; 34/49] END n_neighbors=34;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 34/49] START n_neighbors=34............................................\n",
      "[CV 5/5; 34/49] END n_neighbors=34;, score=(train=0.953, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 1/5; 35/49] END n_neighbors=35;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 2/5; 35/49] END n_neighbors=35;, score=(train=0.953, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 3/5; 35/49] END n_neighbors=35;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 4/5; 35/49] END n_neighbors=35;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 35/49] START n_neighbors=35............................................\n",
      "[CV 5/5; 35/49] END n_neighbors=35;, score=(train=0.954, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 1/5; 36/49] END n_neighbors=36;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 2/5; 36/49] END n_neighbors=36;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 3/5; 36/49] END n_neighbors=36;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 4/5; 36/49] END n_neighbors=36;, score=(train=0.955, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 36/49] START n_neighbors=36............................................\n",
      "[CV 5/5; 36/49] END n_neighbors=36;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 1/5; 37/49] END n_neighbors=37;, score=(train=0.952, test=0.949) total time=   0.1s\n",
      "[CV 2/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 2/5; 37/49] END n_neighbors=37;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 3/5; 37/49] END n_neighbors=37;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 4/5; 37/49] END n_neighbors=37;, score=(train=0.954, test=0.951) total time=   0.1s\n",
      "[CV 5/5; 37/49] START n_neighbors=37............................................\n",
      "[CV 5/5; 37/49] END n_neighbors=37;, score=(train=0.954, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 1/5; 38/49] END n_neighbors=38;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 2/5; 38/49] END n_neighbors=38;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 3/5; 38/49] END n_neighbors=38;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 4/5; 38/49] END n_neighbors=38;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 38/49] START n_neighbors=38............................................\n",
      "[CV 5/5; 38/49] END n_neighbors=38;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 1/5; 39/49] END n_neighbors=39;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 2/5; 39/49] END n_neighbors=39;, score=(train=0.950, test=0.959) total time=   0.1s\n",
      "[CV 3/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 3/5; 39/49] END n_neighbors=39;, score=(train=0.955, test=0.950) total time=   0.1s\n",
      "[CV 4/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 4/5; 39/49] END n_neighbors=39;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 39/49] START n_neighbors=39............................................\n",
      "[CV 5/5; 39/49] END n_neighbors=39;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 1/5; 40/49] END n_neighbors=40;, score=(train=0.952, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 40/49] START n_neighbors=40............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/49] END n_neighbors=40;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 3/5; 40/49] END n_neighbors=40;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 4/5; 40/49] END n_neighbors=40;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 40/49] START n_neighbors=40............................................\n",
      "[CV 5/5; 40/49] END n_neighbors=40;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 1/5; 41/49] END n_neighbors=41;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 2/5; 41/49] END n_neighbors=41;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 3/5; 41/49] END n_neighbors=41;, score=(train=0.954, test=0.947) total time=   0.1s\n",
      "[CV 4/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 4/5; 41/49] END n_neighbors=41;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 41/49] START n_neighbors=41............................................\n",
      "[CV 5/5; 41/49] END n_neighbors=41;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 1/5; 42/49] END n_neighbors=42;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 2/5; 42/49] END n_neighbors=42;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 3/5; 42/49] END n_neighbors=42;, score=(train=0.954, test=0.946) total time=   0.1s\n",
      "[CV 4/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 4/5; 42/49] END n_neighbors=42;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 42/49] START n_neighbors=42............................................\n",
      "[CV 5/5; 42/49] END n_neighbors=42;, score=(train=0.953, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 1/5; 43/49] END n_neighbors=43;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 2/5; 43/49] END n_neighbors=43;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 3/5; 43/49] END n_neighbors=43;, score=(train=0.954, test=0.947) total time=   0.1s\n",
      "[CV 4/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 4/5; 43/49] END n_neighbors=43;, score=(train=0.954, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 43/49] START n_neighbors=43............................................\n",
      "[CV 5/5; 43/49] END n_neighbors=43;, score=(train=0.953, test=0.952) total time=   0.1s\n",
      "[CV 1/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 1/5; 44/49] END n_neighbors=44;, score=(train=0.952, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 2/5; 44/49] END n_neighbors=44;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 3/5; 44/49] END n_neighbors=44;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 4/5; 44/49] END n_neighbors=44;, score=(train=0.953, test=0.950) total time=   0.1s\n",
      "[CV 5/5; 44/49] START n_neighbors=44............................................\n",
      "[CV 5/5; 44/49] END n_neighbors=44;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 1/5; 45/49] END n_neighbors=45;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 2/5; 45/49] END n_neighbors=45;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 3/5; 45/49] END n_neighbors=45;, score=(train=0.954, test=0.947) total time=   0.1s\n",
      "[CV 4/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 4/5; 45/49] END n_neighbors=45;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 45/49] START n_neighbors=45............................................\n",
      "[CV 5/5; 45/49] END n_neighbors=45;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 1/5; 46/49] END n_neighbors=46;, score=(train=0.952, test=0.950) total time=   0.1s\n",
      "[CV 2/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 2/5; 46/49] END n_neighbors=46;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 3/5; 46/49] END n_neighbors=46;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 4/5; 46/49] END n_neighbors=46;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 5/5; 46/49] START n_neighbors=46............................................\n",
      "[CV 5/5; 46/49] END n_neighbors=46;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 1/5; 47/49] END n_neighbors=47;, score=(train=0.953, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 2/5; 47/49] END n_neighbors=47;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 3/5; 47/49] END n_neighbors=47;, score=(train=0.953, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 4/5; 47/49] END n_neighbors=47;, score=(train=0.954, test=0.948) total time=   0.1s\n",
      "[CV 5/5; 47/49] START n_neighbors=47............................................\n",
      "[CV 5/5; 47/49] END n_neighbors=47;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 1/5; 48/49] END n_neighbors=48;, score=(train=0.952, test=0.951) total time=   0.1s\n",
      "[CV 2/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 2/5; 48/49] END n_neighbors=48;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 3/5; 48/49] END n_neighbors=48;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 4/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 4/5; 48/49] END n_neighbors=48;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 48/49] START n_neighbors=48............................................\n",
      "[CV 5/5; 48/49] END n_neighbors=48;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "[CV 1/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 1/5; 49/49] END n_neighbors=49;, score=(train=0.952, test=0.952) total time=   0.1s\n",
      "[CV 2/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 2/5; 49/49] END n_neighbors=49;, score=(train=0.951, test=0.958) total time=   0.1s\n",
      "[CV 3/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 3/5; 49/49] END n_neighbors=49;, score=(train=0.953, test=0.948) total time=   0.1s\n",
      "[CV 4/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 4/5; 49/49] END n_neighbors=49;, score=(train=0.954, test=0.949) total time=   0.1s\n",
      "[CV 5/5; 49/49] START n_neighbors=49............................................\n",
      "[CV 5/5; 49/49] END n_neighbors=49;, score=(train=0.952, test=0.953) total time=   0.1s\n",
      "{'n_neighbors': 36}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 50))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=True,verbose=10)\n",
    "\n",
    "# Taking only 20% of data due to hardware issues\n",
    "gx, f, gy, ff = train_test_split(f_train_val, y_train_val, test_size=0.8, random_state=1, stratify=y_train_val)\n",
    "\n",
    "grid_search=grid.fit(gx, gy)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f4fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighbors = []\n",
    "l = []\n",
    "for i, p in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    neighbors.append({'neighbor': i+1, 'score': p})\n",
    "    l.append(i+1)\n",
    "\n",
    "neighbors.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(l,grid.cv_results_['mean_test_score'])\n",
    "ax.set_ylim([0.9, 0.96])\n",
    "plt.title('GridSearchCV Results')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Nearest Neighbor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9afbc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      3068\n",
      "           1       0.82      0.83      0.83      3068\n",
      "\n",
      "    accuracy                           0.83      6136\n",
      "   macro avg       0.83      0.83      0.83      6136\n",
      "weighted avg       0.83      0.83      0.83      6136\n",
      "\n",
      "KNN 0.8251303780964798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "knn.fit(f_train_val, y_train_val)\n",
    "preds = knn.predict(f_test)\n",
    "preds_proba = knn.predict_proba(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14510656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=neighbors[0]['neighbor'])\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=neighbors[1]['neighbor'])\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=neighbors[2]['neighbor'])\n",
    "\n",
    "knn4 = KNeighborsClassifier(n_neighbors=neighbors[3]['neighbor'])\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=neighbors[4]['neighbor'])\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('knn1', knn1),\n",
    "                                     ('knn2', knn2),\n",
    "                                    ('knn3', knn3),\n",
    "                                     ('knn4', knn4),\n",
    "                                     ('knn5', knn5),\n",
    "                                    ], voting='soft')\n",
    "\n",
    "eclf1.fit(f_train_val, y_train_val)\n",
    "\n",
    "preds = eclf1.predict(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f11ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      3068\n",
      "           1       0.82      0.83      0.83      3068\n",
      "\n",
      "    accuracy                           0.83      6136\n",
      "   macro avg       0.83      0.83      0.83      6136\n",
      "weighted avg       0.83      0.83      0.83      6136\n",
      "\n",
      "KNN VOTING 0.825619295958279\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(\"KNN VOTING\", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe0c01c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      3068\n",
      "           1       0.82      0.84      0.83      3068\n",
      "\n",
      "    accuracy                           0.83      6136\n",
      "   macro avg       0.83      0.83      0.83      6136\n",
      "weighted avg       0.83      0.83      0.83      6136\n",
      "\n",
      "SVM  0.8251303780964798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=3)\n",
    "svclassifier.fit(f_train_val, y_train_val)\n",
    "preds = svclassifier.predict(f_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"SVM \", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998f618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c3e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123d9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
